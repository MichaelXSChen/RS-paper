\section{Implementation Details} \label{sec:impl}

This section first presents our parallel input logging mechanism 
(\S\ref{sec:logging}) for storing inputs efficiently, and then our 
checkpoint/restore mechanism for recovering and adding replicas 
(\S\ref{sec:checkpoint}).

\subsection{Parallel Input Logging} \label{sec:logging}

To handle replica failovers, a standard \paxos protocol should provide a 
persistent input logging storage. \xxx uses the \paxos viewstamp of each input 
as key and its payload as value. \xxx stores this key-value pair in a Berkely 
DB (BDB) with BTree access method~\cite{berkeleydb} because found this method 
fastest in BerkelyDB.

However, once more inputs are inserted, we found the height of the BTree 
will increase, which caused the key-value insertion time to significantly 
increase. To handle this issue, we Implementated a thread-safe, parallel 
logging approach~\cite{para-log:atc10}: instead of maintaining a single BDB 
storage, we maintain an array of BDB stores. We use an index to indicate the 
current active store and insert new inputs, and once the number of insertions 
reach a threshold, we move the index to the next, empty store in the array and 
recycle the previous stores. This parallal logging approach kept our input 
logging latency around 3 to 7 \us, and efficient and stable range 
(\S\ref{sec:overhead}).

\subsection{Checkpoint and Restore} \label{sec:checkpoint}

We proactively design our checkpoint mechanisms to have little performance 
impact in normal case. In short, a checkpoint operation is invoked periodically 
in one backup replica, so the leader and other backups can still reach 
consensus on new inputs efficiently.

% Regularly: periodically checkpoint. Contain both process state and file 
% system state, so that we do not need to check output to file system.
A guard process is running on each replica to checkpoint and restore the local 
server program. The guard does two tasks. First, \xxx assigns one backup 
replica's guard to checkpoint the local server program's process state and file 
system state of current working directory within a physical duration 
\tcheckpoint (one hour in \xxx).

Such a checkpoint operation and its duration are not sensitive to \xxx's 
performance because the other backups can still reach quorum rapidly. Each 
checkpoint is associate with a last committed socket call viewstamp of the 
server program. After each checkpoint, the backup dispatches the checkpoint zip 
file to the other replicas.

Specifically, \xxx leverages CRIU, a popular, open source process checkpoint 
tool, to checkpoint a server program's process state (\eg, CPU registers and 
memory). Since CRIU does not support checkpointing RDMA connections, \xxx's 
guard first sends a ``close RDMA QP" request to an \xxx internal thread, lets 
this thread closes all remote RDMA QPs, and then invokes CRIU to do the 
checkpoint.

The second task for guards is that all guards in all alive replicas handle 
rollback requests once divergence is detected (\S\ref{sec:output-workflow}). 
According to the rollback workflow, a backup guard which receives a rollback 
request from the leader guard will kill the local server process and roll back 
to a previous checkpoint before the last successful hash check.



