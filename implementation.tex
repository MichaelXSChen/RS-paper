\section{Implementation Details} \label{sec:impl}

This section first presents our parallel input logging mechanism 
(\S\ref{sec:logging}) for storing inputs efficiently, and then our 
checkpoint/restore mechanism for recovering and adding replicas 
(\S\ref{sec:checkpoint}).

\subsection{Parallel Input Logging} \label{sec:logging}

To handle replica fail-overs, a standard \paxos protocol should provide a 
persistent input logging storage. \xxx uses the \paxos viewstamp of each input 
as key and its input data as value. \xxx stores this key-value pair in 
Berkeley DB (BDB) with a BTree access method~\cite{berkeleydb}, because found 
this method fastest in our evaluation.

However, if more inputs are inserted, the BTree height 
will increase, which will cause the key-value insertion latency to 
largely increase.

To handle this issue, we implemented a thread-safe, 
parallel logging approach~\cite{Bessani:usenix13}: instead of maintaining a 
single BDB store, we maintain an array of BDB stores. We use an index to 
indicate the current active store and insert new inputs. Once the number of 
insertions reach a threshold, we move the index to the next empty store in the 
array and recycle the preceding stores. This Implementation efficiently kept our 
input logging latency within 2.8$\sim$8.7 \us (\S\ref{sec:overhead}).

\subsection{Checkpoint and Restore} \label{sec:checkpoint}

We proactively design \xxx's checkpoint mechanism to incur little performance 
impact in normal case. A checkpoint operation is invoked periodically 
in one backup replica, so the leader and other backups can still reach 
consensus on new inputs rapidly.

% Regularly: periodically checkpoint. Contain both process state and file 
% system state, so that we do not need to check output to file system.
A guard process is running on each replica to checkpoint and restore the 
local server program. It assigns one backup 
replica's guard to checkpoint the local server program's process state and file 
system state of current working directory within a one-minute duration.

Such a checkpoint operation and its duration are not sensitive to normal case
performance because the other backups can still reach quorum rapidly. Each 
checkpoint is associate with a last committed socket call viewstamp of the 
server program. After each checkpoint, the backup dispatches the checkpoint zip 
file to the other replicas.

Specifically, \xxx leverages CRIU, a popular, open source process checkpoint 
tool, to checkpoint a server program's process state (\eg, CPU registers and 
memory). Since CRIU does not support checkpointing RDMA connections, \xxx's 
guard first sends a ``close RDMA QP" request to an \xxx internal thread, lets 
this thread closes all remote RDMA QPs, and then invokes CRIU to do the 
checkpoint.

% The second task for guards is that all guards in all alive replicas handle 
% rollback requests once divergence is detected (\S\ref{sec:output-workflow}). 
% According to the rollback workflow, a backup guard which receives a rollback 
% request from the leader guard will kill the local server process and roll back 
% to a previous checkpoint before the last successful hash check.



